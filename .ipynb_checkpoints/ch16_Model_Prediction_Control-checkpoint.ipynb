{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc3da69-69a0-47fe-8f98-30a77e52254c",
   "metadata": {},
   "source": [
    "# 第 16 章 模型预测控制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160948f-b765-42d7-8bf2-2e364d403a83",
   "metadata": {},
   "source": [
    "## 16.1 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f81e6-905a-4959-bac3-0ffc7c313c5f",
   "metadata": {},
   "source": [
    "之前几章介绍了基于值函数的方法 DQN、基于策略的方法 REINFORCE 以及两者结合的方法 Actor-Critic。它们都是无模型（model-free）的方法，即没有建立一个环境模型来帮助智能体决策。而在深度强化学习领域下，基于模型（model-based）的方法通常用神经网络学习一个环境模型，然后利用该环境模型来帮助智能体训练和决策。利用环境模型帮助智能体训练和决策的方法有很多种，例如可以用与之前的 Dyna 类似的思想生成一些数据来加入策略训练中。本章要介绍的模型预测控制（model predictive control，MPC）算法并不构建一个显式的策略，只根据环境模型来选择当前步要采取的动作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187a9d0-fc7f-49ff-9e25-cb4c9bb4205c",
   "metadata": {},
   "source": [
    "## 16.2 打靶法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8283a-589a-4dbf-8e02-9cd57af8864a",
   "metadata": {},
   "source": [
    "首先，让我们用一个形象的比喻来帮助理解模型预测控制方法。假设我们在下围棋，现在根据棋盘的布局，我们要选择现在落子的位置。一个优秀的棋手会根据目前局势来推演落子几步可能发生的局势，然后选择局势最好的一种情况来决定当前落子位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597a393-53e7-4cd0-9810-7de3dab3f997",
   "metadata": {},
   "source": [
    "模型预测控制方法就是这样一种迭代的、基于模型的控制方法。值得注意的是，MPC 方法中不存在一个显式的策略。具体而言，MPC 方法在每次采取动作时，首先会生成一些候选动作序列，然后根据当前状态来确定每一条候选序列能得到多好的结果，最终选择结果最好的那条动作序列的第一个动作来执行。因此，在使用 MPC 方法时，主要在两个过程中迭代，一是根据历史数据学习环境模型 $\\hat{P}(s,a)$，二是在和真实环境交互过程中用环境模型来选择动作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9e88d-4a98-480f-a5bb-17385496acac",
   "metadata": {},
   "source": [
    "首先，我们定义模型预测方法的目标。在第K步时，我们要想做的就是最大化智能体的累积奖励，具体来说就是："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d01c9aa-9dac-47a6-8941-9bfd83cfb683",
   "metadata": {},
   "source": [
    "### 16.2.1 随机打靶法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7436898e-b58b-4672-a044-d155cc72ccef",
   "metadata": {},
   "source": [
    "随机打靶法（random shooting method）的做法便是随机生成$N$条动作序列，即在生成每条动作序列的每一个动作时，都是从动作空间中随机采样一个动作，最终组合成$N$条长度为$H$的动作序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e462d-c047-4a6b-9a71-727070e5d265",
   "metadata": {},
   "source": [
    "对于一些简单的环境，这个方法不但十分简单，而且效果还不错。那么，能不能在随机的基础上，根据已有的结果做得更好一些呢？接下来，我们来介绍另外一种打靶法：交叉熵方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be4eee-49c2-4601-9445-08902304c8a3",
   "metadata": {},
   "source": [
    "### 16.2.2 交叉熵方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55579a3f-7bd8-403d-ad42-124043f4284d",
   "metadata": {},
   "source": [
    "交叉熵方法（cross entropy method，CEM）是一种进化策略方法，它的核心思想是维护一个带参数的分布，根据每次采样的结果来更新分布中的参数，使得分布中能获得较高累积奖励的动作序列的概率比较高。相比于随机打靶法，交叉熵方法能够利用之前采样到的比较好的结果，在一定程度上减少采样到一些较差动作的概率，从而使得算法更加高效。对于一个与连续动作交互的环境来说，每次交互时交叉熵方法的做法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e0b32-d60d-4a5f-b7a0-24ca3f49d49d",
   "metadata": {},
   "source": [
    "我们可以使用如下的代码来实现交叉熵方法，其中将采用截断正态分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62177a6e-c947-4447-9116-c54924138203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import gym\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CEM:\n",
    "    def __init__(self, n_sequence, elite_ratio, fake_env, upper_bound,\n",
    "                 lower_bound):\n",
    "        self.n_sequence = n_sequence\n",
    "        self.elite_ratio = elite_ratio\n",
    "        self.upper_bound = upper_bound\n",
    "        self.lower_bound = lower_bound\n",
    "        self.fake_env = fake_env\n",
    "\n",
    "    def optimize(self, state, init_mean, init_var):\n",
    "        mean, var = init_mean, init_var\n",
    "        X = truncnorm(-2, 2, loc=np.zeros_like(mean), scale=np.ones_like(var))\n",
    "        state = np.tile(state, (self.n_sequence, 1))\n",
    "\n",
    "        for _ in range(5):\n",
    "            lb_dist, ub_dist = mean - self.lower_bound, self.upper_bound - mean\n",
    "            constrained_var = np.minimum(\n",
    "                np.minimum(np.square(lb_dist / 2), np.square(ub_dist / 2)),\n",
    "                var)\n",
    "            # 生成动作序列\n",
    "            action_sequences = [X.rvs() for _ in range(self.n_sequence)\n",
    "                                ] * np.sqrt(constrained_var) + mean\n",
    "            # 计算每条动作序列的累积奖励\n",
    "            returns = self.fake_env.propagate(state, action_sequences)[:, 0]\n",
    "            # 选取累积奖励最高的若干条动作序列\n",
    "            elites = action_sequences[np.argsort(\n",
    "                returns)][-int(self.elite_ratio * self.n_sequence):]\n",
    "            new_mean = np.mean(elites, axis=0)\n",
    "            new_var = np.var(elites, axis=0)\n",
    "            # 更新动作序列分布\n",
    "            mean = 0.1 * mean + 0.9 * new_mean\n",
    "            var = 0.1 * var + 0.9 * new_var\n",
    "\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb912b1a-8ebd-491b-b10d-0f8eaacddf43",
   "metadata": {},
   "source": [
    "## 16.3 PETS 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39e175-6b7a-4a11-839b-298ecf570276",
   "metadata": {},
   "source": [
    "带有轨迹采样的概率集成（probabilistic ensembles with trajectory sampling，PETS）是一种使用 MPC 的基于模型的强化学习算法。在 PETS 中，环境模型采用了集成学习的方法，即会构建多个环境模型，然后用这多个环境模型来进行预测，最后使用 CEM 进行模型预测控制。接下来，我们来详细介绍模型构建与模型预测的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c29aa-6f02-4901-89b0-7e29f24c828f",
   "metadata": {},
   "source": [
    "在强化学习中，与智能体交互的环境是一个动态系统，所以拟合它的环境模型也通常是一个动态模型。我们通常认为一个系统中有两种不确定性，分别是偶然不确定性（aleatoric uncertainty）和认知不确定性（epistemic uncertainty）。偶然不确定性是由于系统中本身存在的随机性引起的，而认知不确定性是由“见”过的数据较少导致的自身认知的不足而引起的，如图 16-1 所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c81e5-5965-4720-9c5f-73ab71e9e2c8",
   "metadata": {},
   "source": [
    "## 16.4 PETS 算法实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515f082-4bc5-4534-a2c8-f03bb6c6c96a",
   "metadata": {},
   "source": [
    "首先，为了搭建这样一个较为复杂的模型，我们定义模型中每一层的构造。在定义时就必须考虑每一层都是一个集成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4bd300d-c953-4173-9505-0c9c73263c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    ''' Swish激活函数 '''\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    ''' 初始化模型权重 '''\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)\n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)\n",
    "            if not torch.sum(cond):\n",
    "                break\n",
    "            t = torch.where(\n",
    "                cond,\n",
    "                torch.nn.init.normal_(torch.ones(t.shape, device=device),\n",
    "                                      mean=mean,\n",
    "                                      std=std), t)\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    ''' 集成之后的全连接层 '''\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(\n",
    "            torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b606c44-14a7-4249-8de3-2a0e218e3082",
   "metadata": {},
   "source": [
    "接着，使用高斯分布的概率模型来定义一个集成模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9d5a1eb-208e-4873-afc5-a601b5db0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    ''' 环境模型集成 '''\n",
    "    def __init__(self,\n",
    "                 state_dim,\n",
    "                 action_dim,\n",
    "                 ensemble_size=5,\n",
    "                 learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        # 输出包括均值和方差,因此是状态与奖励维度之和的两倍\n",
    "        self._output_dim = (state_dim + 1) * 2\n",
    "        self._max_logvar = nn.Parameter((torch.ones(\n",
    "            (1, self._output_dim // 2)).float() / 2).to(device),\n",
    "                                        requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones(\n",
    "            (1, self._output_dim // 2)).float() * 10).to(device),\n",
    "                                        requires_grad=False)\n",
    "\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size,\n",
    "                              Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size,\n",
    "                              nn.Identity())\n",
    "        self.apply(init_weights)  # 初始化环境模型中的参数\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(\n",
    "            self.layer1(x)))))\n",
    "        mean = ret[:, :, :self._output_dim // 2]\n",
    "        # 在PETS算法中,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(\n",
    "            self._max_logvar - ret[:, :, self._output_dim // 2:])\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) *\n",
    "                                             inverse_var,\n",
    "                                             dim=-1),\n",
    "                                  dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss += 0.01 * torch.sum(self._max_logvar) - 0.01 * torch.sum(\n",
    "            self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86b7ff-27ea-41a8-9cd0-da31ac3a7b62",
   "metadata": {},
   "source": [
    "接下来，我们定义一个EnsembleDynamicsModel的类，把模型集成的训练设计得更加精细化。具体而言，我们并不会选择模型训练的轮数，而是在每次训练的时候将一部分数据单独取出来，用于验证模型的表现，在 5 次没有获得表现提升时就结束训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05e3a724-59c2-4a8d-b63a-7bc16fa92da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleDynamicsModel:\n",
    "    ''' 环境模型集成,加入精细化的训练 '''\n",
    "    def __init__(self, state_dim, action_dim, num_network=5):\n",
    "        self._num_network = num_network\n",
    "        self._state_dim, self._action_dim = state_dim, action_dim\n",
    "        self.model = EnsembleModel(state_dim,\n",
    "                                   action_dim,\n",
    "                                   ensemble_size=num_network)\n",
    "        self._epoch_since_last_update = 0\n",
    "\n",
    "    def train(self,\n",
    "              inputs,\n",
    "              labels,\n",
    "              batch_size=64,\n",
    "              holdout_ratio=0.1,\n",
    "              max_iter=20):\n",
    "        # 设置训练集与验证集\n",
    "        permutation = np.random.permutation(inputs.shape[0])\n",
    "        inputs, labels = inputs[permutation], labels[permutation]\n",
    "        num_holdout = int(inputs.shape[0] * holdout_ratio)\n",
    "        train_inputs, train_labels = inputs[num_holdout:], labels[num_holdout:]\n",
    "        holdout_inputs, holdout_labels = inputs[:\n",
    "                                                num_holdout], labels[:\n",
    "                                                                     num_holdout]\n",
    "        holdout_inputs = torch.from_numpy(holdout_inputs).float().to(device)\n",
    "        holdout_labels = torch.from_numpy(holdout_labels).float().to(device)\n",
    "        holdout_inputs = holdout_inputs[None, :, :].repeat(\n",
    "            [self._num_network, 1, 1])\n",
    "        holdout_labels = holdout_labels[None, :, :].repeat(\n",
    "            [self._num_network, 1, 1])\n",
    "\n",
    "        # 保留最好的结果\n",
    "        self._snapshots = {i: (None, 1e10) for i in range(self._num_network)}\n",
    "\n",
    "        for epoch in itertools.count():\n",
    "            # 定义每一个网络的训练数据\n",
    "            train_index = np.vstack([\n",
    "                np.random.permutation(train_inputs.shape[0])\n",
    "                for _ in range(self._num_network)\n",
    "            ])\n",
    "            # 所有真实数据都用来训练\n",
    "            for batch_start_pos in range(0, train_inputs.shape[0], batch_size):\n",
    "                batch_index = train_index[:, batch_start_pos:batch_start_pos +\n",
    "                                          batch_size]\n",
    "                train_input = torch.from_numpy(\n",
    "                    train_inputs[batch_index]).float().to(device)\n",
    "                train_label = torch.from_numpy(\n",
    "                    train_labels[batch_index]).float().to(device)\n",
    "\n",
    "                mean, logvar = self.model(train_input, return_log_var=True)\n",
    "                loss, _ = self.model.loss(mean, logvar, train_label)\n",
    "                self.model.train(loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                mean, logvar = self.model(holdout_inputs, return_log_var=True)\n",
    "                _, holdout_losses = self.model.loss(mean,\n",
    "                                                    logvar,\n",
    "                                                    holdout_labels,\n",
    "                                                    use_var_loss=False)\n",
    "                holdout_losses = holdout_losses.cpu()\n",
    "                break_condition = self._save_best(epoch, holdout_losses)\n",
    "                if break_condition or epoch > max_iter:  # 结束训练\n",
    "                    break\n",
    "\n",
    "    def _save_best(self, epoch, losses, threshold=0.1):\n",
    "        updated = False\n",
    "        for i in range(len(losses)):\n",
    "            current = losses[i]\n",
    "            _, best = self._snapshots[i]\n",
    "            improvement = (best - current) / best\n",
    "            if improvement > threshold:\n",
    "                self._snapshots[i] = (epoch, current)\n",
    "                updated = True\n",
    "        self._epoch_since_last_update = 0 if updated else self._epoch_since_last_update + 1\n",
    "        return self._epoch_since_last_update > 5\n",
    "\n",
    "    def predict(self, inputs, batch_size=64):\n",
    "        mean, var = [], []\n",
    "        for i in range(0, inputs.shape[0], batch_size):\n",
    "            input = torch.from_numpy(\n",
    "                inputs[i:min(i +\n",
    "                             batch_size, inputs.shape[0])]).float().to(device)\n",
    "            cur_mean, cur_var = self.model(input[None, :, :].repeat(\n",
    "                [self._num_network, 1, 1]),\n",
    "                                           return_log_var=False)\n",
    "            mean.append(cur_mean.detach().cpu().numpy())\n",
    "            var.append(cur_var.detach().cpu().numpy())\n",
    "        return np.hstack(mean), np.hstack(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e11b4c-a27f-4ea6-ad26-72b080c640bc",
   "metadata": {},
   "source": [
    "有了环境模型之后，我们就可以定义一个FakeEnv，主要用于实现给定状态和动作，用模型集成来进行预测。该功能会用在 MPC 算法中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c4c2f3a-41dd-4521-997e-0c3acb640128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeEnv:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, obs, act):\n",
    "        inputs = np.concatenate((obs, act), axis=-1)\n",
    "        ensemble_model_means, ensemble_model_vars = self.model.predict(inputs)\n",
    "        ensemble_model_means[:, :, 1:] += obs.numpy()\n",
    "        ensemble_model_stds = np.sqrt(ensemble_model_vars)\n",
    "        ensemble_samples = ensemble_model_means + np.random.normal(\n",
    "            size=ensemble_model_means.shape) * ensemble_model_stds\n",
    "\n",
    "        num_models, batch_size, _ = ensemble_model_means.shape\n",
    "        models_to_use = np.random.choice(\n",
    "            [i for i in range(self.model._num_network)], size=batch_size)\n",
    "        batch_inds = np.arange(0, batch_size)\n",
    "        samples = ensemble_samples[models_to_use, batch_inds]\n",
    "        rewards, next_obs = samples[:, :1], samples[:, 1:]\n",
    "        return rewards, next_obs\n",
    "\n",
    "    def propagate(self, obs, actions):\n",
    "        with torch.no_grad():\n",
    "            obs = np.copy(obs)\n",
    "            total_reward = np.expand_dims(np.zeros(obs.shape[0]), axis=-1)\n",
    "            obs, actions = torch.as_tensor(obs), torch.as_tensor(actions)\n",
    "            for i in range(actions.shape[1]):\n",
    "                action = torch.unsqueeze(actions[:, i], 1)\n",
    "                rewards, next_obs = self.step(obs, action)\n",
    "                total_reward += rewards\n",
    "                obs = torch.as_tensor(next_obs)\n",
    "            return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd1a9c-7e23-4647-acbf-beb2d07a999d",
   "metadata": {},
   "source": [
    "接下来定义经验回放池的类Replay Buffer。与之前的章节对比，此处经验回放缓冲区会额外实现一个返回所有数据的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76e058da-8cf1-4478-8112-474601354c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def return_all_samples(self):\n",
    "        all_transitions = list(self.buffer)\n",
    "        state, action, reward, next_state, done = zip(*all_transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72026e78-f7fe-4711-9c75-c461d51beba8",
   "metadata": {},
   "source": [
    "接下来是 PETS 算法的主体部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20986278-de2b-48d6-bcbf-cdd12458f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PETS:\n",
    "    ''' PETS算法 '''\n",
    "    def __init__(self, env, replay_buffer, n_sequence, elite_ratio,\n",
    "                 plan_horizon, num_episodes):\n",
    "        self._env = env\n",
    "        self._env_pool = replay_buffer\n",
    "\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        self._action_dim = env.action_space.shape[0]\n",
    "        self._model = EnsembleDynamicsModel(obs_dim, self._action_dim)\n",
    "        self._fake_env = FakeEnv(self._model)\n",
    "        self.upper_bound = env.action_space.high[0]\n",
    "        self.lower_bound = env.action_space.low[0]\n",
    "\n",
    "        self._cem = CEM(n_sequence, elite_ratio, self._fake_env,\n",
    "                        self.upper_bound, self.lower_bound)\n",
    "        self.plan_horizon = plan_horizon\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    def train_model(self):\n",
    "        env_samples = self._env_pool.return_all_samples()\n",
    "        obs = env_samples[0]\n",
    "        actions = np.array(env_samples[1])\n",
    "        rewards = np.array(env_samples[2]).reshape(-1, 1)\n",
    "        next_obs = env_samples[3]\n",
    "        inputs = np.concatenate((obs, actions), axis=-1)\n",
    "        labels = np.concatenate((rewards, next_obs - obs), axis=-1)\n",
    "        self._model.train(inputs, labels)\n",
    "\n",
    "    def mpc(self):\n",
    "        mean = np.tile((self.upper_bound + self.lower_bound) / 2.0,\n",
    "                       self.plan_horizon)\n",
    "        var = np.tile(\n",
    "            np.square(self.upper_bound - self.lower_bound) / 16,\n",
    "            self.plan_horizon)\n",
    "        obs, done, episode_return = self._env.reset(), False, 0\n",
    "        while not done:\n",
    "            actions = self._cem.optimize(obs, mean, var)\n",
    "            action = actions[:self._action_dim]  # 选取第一个动作\n",
    "            next_obs, reward, done, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "            mean = np.concatenate([\n",
    "                np.copy(actions)[self._action_dim:],\n",
    "                np.zeros(self._action_dim)\n",
    "            ])\n",
    "        return episode_return\n",
    "\n",
    "    def explore(self):\n",
    "        obs, done, episode_return = self._env.reset(), False, 0\n",
    "        while not done:\n",
    "            action = self._env.action_space.sample()\n",
    "            next_obs, reward, done, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "        return episode_return\n",
    "\n",
    "    def train(self):\n",
    "        return_list = []\n",
    "        explore_return = self.explore()  # 先进行随机策略的探索来收集一条序列的数据\n",
    "        print('episode: 1, return: %d' % explore_return)\n",
    "        return_list.append(explore_return)\n",
    "\n",
    "        for i_episode in range(self.num_episodes - 1):\n",
    "            self.train_model()\n",
    "            episode_return = self.mpc()\n",
    "            return_list.append(episode_return)\n",
    "            print('episode: %d, return: %d' % (i_episode + 2, episode_return))\n",
    "        return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173c8c3-4acc-4c07-be1b-73550a818702",
   "metadata": {},
   "source": [
    "大功告成！让我们在倒立摆环境上试一下吧，以下代码需要一定的运行时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d02d822-17ee-420d-875a-0580a81a6475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, return: -1062\n",
      "episode: 2, return: -1544\n",
      "episode: 3, return: -1716\n",
      "episode: 4, return: -934\n",
      "episode: 5, return: -538\n",
      "episode: 6, return: -517\n",
      "episode: 7, return: -121\n",
      "episode: 8, return: -123\n",
      "episode: 9, return: -124\n",
      "episode: 10, return: -121\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer_size = 100000\n",
    "n_sequence = 50\n",
    "elite_ratio = 0.2\n",
    "plan_horizon = 25\n",
    "num_episodes = 10\n",
    "# WARN: The environment Pendulum-v0 is out of date. \n",
    "# You should consider upgrading to version `v1`.\n",
    "env_name = 'Pendulum-v1'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "pets = PETS(env, replay_buffer, n_sequence, elite_ratio, plan_horizon,\n",
    "            num_episodes)\n",
    "return_list = pets.train()\n",
    "\n",
    "episodes_list = list(range(len(return_list)))\n",
    "plt.plot(episodes_list, return_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('PETS on {}'.format(env_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343b189-59be-4c7a-b0a8-94f1fba0ccba",
   "metadata": {},
   "source": [
    "可以看出，PETS 算法的效果非常好，但是由于每次选取动作都需要在环境模型上进行大量的模拟，因此运行速度非常慢。与 SAC 算法的结果进行对比可以看出，PETS 算法大大提高了样本效率，在比 SAC 算法的环境交互次数少得多的情况下就取得了差不多的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a3240-0fb9-4731-b63e-8147ed2de9a1",
   "metadata": {},
   "source": [
    "## 16.5 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68266c03-9c88-44f3-8548-0e32dd1726b5",
   "metadata": {},
   "source": [
    "通过学习与实践，我们可以看出模型预测控制（MPC）方法有着其独特的优势，例如它不用构建和训练策略，可以更好地利用环境，可以进行更长步数的规划。但是 MPC 也有其局限性，例如模型在多步推演之后的准确性会大大降低，简单的控制策略对于复杂系统可能不够。MPC 还有一个更为严重的问题，即每次计算动作的复杂度太大，这使其在一些策略及时性要求较高的系统中应用就变得不太现实。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f48865-5e92-44be-9732-b5273732df04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ba415-a9d3-40a0-82d1-4be34e0cd149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
